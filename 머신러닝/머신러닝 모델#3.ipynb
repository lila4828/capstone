{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torchvision import datasets ,models , transforms\n","import json\n","from torch.utils.data import Dataset, DataLoader ,random_split\n","from PIL import Image\n","from pathlib import Path\n","classLabels = [\"exotic\", \"cozy\", \"luxurious\", \"nature_freindly\", \"modern\" ]\n","\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bCjDDdEevzWD","outputId":"99a931e2-b3a8-4ce6-c94c-32d986703b97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.1+cu121\n"]}]},{"cell_type":"code","source":["import os\n","import random\n","\n","image_folder_path = 'original2'\n","\n","# 폴더 내의 모든 파일 목록을 가져옵니다.\n","image_files = [os.path.join(image_folder_path, f) for f in os.listdir(image_folder_path) if os.path.isfile(os.path.join(image_folder_path, f))]\n","\n","# 랜덤하게 10개의 이미지를 선택합니다. (이미지 수가 10개 미만일 경우 모든 이미지를 선택)\n","selected_images = random.sample(image_files, min(10, len(image_files)))\n","\n","# 선택된 이미지를 출력합니다.\n","plt.figure(figsize=(20, 10))  # 출력될 이미지 크기를 설정합니다.\n","for i, image_path in enumerate(selected_images):\n","    img = Image.open(image_path)\n","    plt.subplot(2, 5, i + 1)  # 2행 5열의 그리드에서 이미지를 출력합니다.\n","    plt.imshow(img)\n","    plt.axis('off')  # 축을 보이지 않게 합니다.\n","plt.show()"],"metadata":{"id":"lolDqaIaxG_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame({\"image\": sorted([int(x.name.strip(\".jpg\")) for x in Path(\"original\").iterdir()])})\n","df[\"image\"] = df[\"image\"].astype(str) + \".jpg\"\n","\n","df.to_csv(\"data.csv\", index=False)\n","# 데이터프레임의 처음 10개 및 마지막 10개 행 출력\n","print(df.head(10))\n","print(df.tail(10))"],"metadata":{"id":"7qm47QhVydGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualizeImage(idx):\n","    fd = df.iloc[idx]\n","    image = fd['image']\n","    label = fd[1:].to_numpy()\n","    print(image)\n","    image = Image.open(\"original2/\" + image)\n","    fig, ax = plt.subplots()\n","    ax.imshow(image)\n","    ax.grid(False)\n","    classes = np.array(classLabels)[label.astype(np.bool_)]  # np.bool 대신 np.bool_ 사용\n","    for i, s in enumerate(classes):\n","        ax.text(0, i * 20, s, verticalalignment='top', color=\"white\", fontsize=16, weight='bold')\n","    plt.show()\n","\n","visualizeImage(51)"],"metadata":{"id":"TDNuNHxcxTfl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#데이터 피딩을 위한 작업\n","\n","class MyDataset(Dataset):\n","  def __init__(self , csv_file , img_dir , transforms=None ):\n","\n","    self.df = pd.read_csv(csv_file)\n","    self.img_dir = img_dir\n","    self.transforms = transforms\n","\n","  def __getitem__(self,idx):\n","    d = self.df.iloc[idx]\n","    image = Image.open(self.img_dir/d.image).convert(\"RGB\")\n","    label = torch.tensor(d[1:].tolist() , dtype=torch.float32)\n","\n","    if self.transforms is not None:\n","      image = self.transforms(image)\n","    return image,label\n","\n","  def __len__(self):\n","    return len(self.df)"],"metadata":{"id":"UnMiWZLCz_iZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=500\n","transform = transforms.Compose([transforms.Resize((224,224)) ,\n","                               transforms.ToTensor(),\n","                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","                               ])\n","\n","dataset = MyDataset(\"data.csv\" , Path(\"original2\") , transform)\n","\n","valid_no = int(len(dataset) * 0.12)\n","_, valset = random_split(dataset, [len(dataset) - valid_no, valid_no])\n","print(f\"valset len {len(valset)}\")\n","dataloader = {\"val\": DataLoader(valset, shuffle=True, batch_size=batch_size)}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApV1kGPn0CZr","outputId":"d35bd2f5-cc8f-4215-b14c-13b406f52b48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["trainset len 330 valset len 45\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"iQe18kpK0Blw"}},{"cell_type":"code","source":["# resnet50모델로 전이학습 하겠습니다.\n","\n","model = models.resnet50(pretrained=True) # load the pretrained model\n","num_features = model.fc.in_features # get the no of on_features in last Linear unit\n","print(num_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TX8B7bnGytyb","outputId":"0a76859f-59db-436a-8193-00e4748da95c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["2048\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYIgDTDmxa4Z","outputId":"ab8aa42e-3ff8-4b11-a46e-ac5a0b532764"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"code","source":["#loss 함수와 옵티마이져, 스케줄로를 정의\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# specify optimizer\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","sgdr_partial = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0.005 )"],"metadata":{"id":"sw8yw2Y-y52P"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BATP63hYulC7","outputId":"ed5dc5de-205a-448f-800b-4886e099d775"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    initial_lr: 0.001\n","    lr: 0.0009999999999999983\n","    maximize: False\n","    weight_decay: 0\n",")"]},"metadata":{},"execution_count":208}],"source":["#모델 로드 및 추론용으로 세팅\n","'''\n","First Intialize the model and then just load it\n","model = TheModelClass(*args, **kwargs)\n","optimizer = TheOptimizerClass(*args, **kwargs)\n","/content/LatestCheckpoint.pt\n","'''\n","\n","checkpoint = torch.load(Path(\"./LatestCheckpoint.pt\"))\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","epoch = checkpoint['epoch']\n","batch_size = checkpoint['batch_size']\n","\n","model.eval() ## or model.train()\n","optimizer"]},{"cell_type":"code","source":["#valid 데이터로 추론\n","\n","image , label = next(iter(dataloader[\"val\"]))\n","image = image.to(device)\n","label = label.to(device)\n","output = 0\n","with torch.no_grad():\n","  output = model(image)\n","  output = torch.sigmoid(output)\n","output = output>0.2\n","mean , std = torch.tensor([0.485, 0.456, 0.406]),torch.tensor([0.229, 0.224, 0.225])"],"metadata":{"id":"pAp1IzddupGr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["전경 분류"],"metadata":{"id":"tlKCScJJvQo3"}},{"cell_type":"code","source":["import keras\n","from keras.applications import ResNet50\n","from keras.applications.resnet50 import preprocess_input\n","from keras import Model, layers\n","from keras.models import load_model, model_from_json"],"metadata":{"id":"Q84V98N0vR6R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_base = ResNet50(\n","    include_top=False,\n","    weights='imagenet')\n","\n","for layer in conv_base.layers:\n","    layer.trainable = False"],"metadata":{"id":"LaJAvVZ-wVcq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = conv_base.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(128, activation='relu')(x)\n","predictions = layers.Dense(2, activation='softmax')(x)\n","Hmodel = Model(conv_base.input, predictions)"],"metadata":{"id":"0ebUsW4WwVam"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = keras.optimizers.Adam()\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=optimizer,\n","              metrics=['accuracy'])"],"metadata":{"id":"qAP1mXZxwVXV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모델 불러오는 파트"],"metadata":{"id":"JAbwognewiCU"}},{"cell_type":"code","source":["# architecture and weights from HDF5\n","model = load_model('model.h5')\n","\n","# architecture from JSON, weights from HDF5\n","with open('architecture.json') as f:\n","    Hmodel = model_from_json(f.read())\n","model.load_weights('weights.h5')"],"metadata":{"id":"7vPRQH8dvxNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 설정 후 사용\n","# model 설정 코드\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"4yyenHzeIdWV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["분류 파트"],"metadata":{"id":"9gRLMA06_Mmy"}},{"cell_type":"markdown","source":["함수"],"metadata":{"id":"Z3aAm-ovCHtY"}},{"cell_type":"code","source":["def predict_labels(output, class_labels):\n","    predicted_labels = [class_labels[j] for j, pred in enumerate(output) if pred]\n","    return predicted_labels"],"metadata":{"id":"e8_PBgaMJlb4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_labels = predict_labels(output[0], classLabels)\n","print(predicted_labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFxaK6KMcI6v","outputId":"b9d4d407-316e-4178-c349-4a21b32b83f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['luxurious', 'modern']\n"]}]},{"cell_type":"markdown","source":["전경 파트"],"metadata":{"id":"yYhPRWXY_Lar"}},{"cell_type":"markdown","source":["함수"],"metadata":{"id":"UuybHunfwHOD"}},{"cell_type":"code","source":["def predict_cafe(image_path, model):\n","    # 이미지 로드 및 전처리\n","    img = Image.open(image_path).resize((224, 224))\n","    img_array = preprocess_input(np.array(img)[np.newaxis, :])\n","\n","    # 모델 예측\n","    pred_probs = model.predict(img_array)\n","\n","    # 예측 결과 해석 파트\n","    predicted_label = \"Cafe\" if pred_probs[0][0] > 0.8 else \"Non-Cafe\"\n","    #confidence = pred_probs[0][0] if predicted_label == \"Cafe\" else 1 - pred_probs[0][0]\n","\n","\n","    #카페인지 아닌지 return predicted_label, confidence\n","    return predicted_label\n"],"metadata":{"id":"zuSSQF2Z_CCQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#이미지 경로 -> 미리 지정해놓고 사용\n","image_path = \"data/validation/NonCafe/5.jpg\"\n","\n","# 함수 호출\n","predicted_Cafe = predict_cafe(image_path, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4a7NvdgCAKMI","outputId":"e9e29376-0f96-450b-9988-d9fb5d9c9995"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 172ms/step\n"]}]},{"cell_type":"code","source":["print(\"Predicted Cafe:\", predicted_Cafe)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"338kVukr_cxT","outputId":"3787fff0-4f7c-4193-fd26-e45eda75da10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Cafe: Non-Cafe\n"]}]}]}